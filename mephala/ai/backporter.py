"""
Glue between LLM (mephala.ai.Agent) and the pure diff logic.

Backporter(hunk, candidate, cve_record).run() returns a *new* Hunk that
represents the proposed backport.
"""
from __future__ import annotations
import logging
from pathlib import Path

from mephala.ai.agent          import Agent
from mephala.core.models.action    import Action
from mephala.core.models.candidate import Candidate
from mephala.core.models.cve_record import CVERecord
from mephala.core.diff.hunk        import Hunk
from mephala.core.exceptions       import GarbageCandidateError
from mephala.core.utils.patch_checks import validate_structure, triage_diff, is_patch_well_formed

log = logging.getLogger(__name__)


class Backporter:
    """
    Backport pipeline orchestration.
    """

    def __init__(self, hunk: Hunk, candidate: Candidate, cve: CVERecord):
        self.hunk      = hunk
        self.candidate = candidate
        self.cve       = cve
        self.agent     = Agent()   # singleton
        self.struct_errors: list[str] = []
        self.triage_report: str = ""

    # ─────────────────────────────────────────────── public
    def run(self) -> Hunk:
        try:
            draft = self._draft_backport()
    
            if not draft.strip():
                raise GarbageCandidateError("LLM produced empty draft")
    
            actions = self.hunk.generate_actions()
            prune   = self._prune_actions(actions)
            align   = self._align_actions(prune)
            new_hunk = self._weave(align)
            # ─────────────── validation / triage ──────────────────────────
            self.struct_errors = validate_structure(self.hunk, str(new_hunk))
            self.triage_report = triage_diff(self.hunk, new_hunk, self.candidate)
    
            # optional: let the LLM try a one-shot “fix” when the only complaint is indentation
            if self.struct_errors and all("indent" in e.lower() for e in self.struct_errors):
                patch_txt = str(new_hunk)
                fix_prompt = (
                    "The following unified diff is syntactically broken (indentation only).\n"
                    "Please output a *corrected* diff – same filename, keep exact code.\n"
                    "```diff\n" + patch_txt + "\n```"
                )
                try:
                    fixed = self.agent.ask(fix_prompt, pattern="diff", stage="repair_structure")
                    if is_patch_well_formed(fixed):
                        from mephala.core.diff.hunk import Hunk
                        new_hunk = Hunk.from_diff_lines(fixed.splitlines(), new_hunk.filename)
                        self.struct_errors = validate_structure(self.hunk, str(new_hunk))
                except Exception:
                    # even if the LLM fails we keep the original new_hunk
                    pass
            return new_hunk
        finally:
            Agent().new_session()


    # ─────────────────────────────────────────────── steps
    # 1. draft with LLM
    def _draft_backport(self) -> str:
        pattern = self._extension_to_language(Path(self.candidate.path_to).suffix)
        prompt = f"""
Imagine you had a hunk of a patch, generated against version X:
{self.hunk}

It addresses CVE {self.cve.cve}:
{self.cve.desc}

Below is code from the target version where we think the patch must go:
{self.candidate.path_to}:
{self.candidate.context_str()}

Write what that code would look like *after* the patch is applied.
Preserve indentation – do not left-justify.

Respond only with ```{pattern}``` fenced code.
"""
        return self.agent.ask(prompt, pattern=pattern, stage="draft_backport")


    # 2. prune actions via LLM
    def _prune_actions(self, actions: list[Action]) -> list[Action]:
        """
        Decide which actions generated from the template hunk should be
        deleted **before** we attempt to align/weave them.

        Strategy
        --------
        1.  Ask the LLM to classify every target action as
               identical | opposites | irrelevant | other
            and to signal mismatching variable sets.

        2.  Keep only the YAML items that *request deletion* according to
            the rules in the prompt.

        3.  Verify “opposites” really come in pairs that touch (nearly)
            identical text.  Downgrade bogus labels to 'other'.

        4.  If the pruning step would wipe out every action, fall back to
            the original list and log a warning – we never want to enter
            the alignment stage with an empty set.
        """
        # ─── 0. build input dictionaries ────────────────────────────────
        tpl = {f"t.{i}": a for i, a in enumerate(actions)}
        tgt = {f"0-{i}": a for i, a in enumerate(actions)}   # self-diff template

        prompt = f"""
You are reviewing two patch action sequences, each represented as an ordered dictionary:
- The *template sequence* (original patch actions): {self._dict_str(tpl)}
- The *target   sequence* (actions generated by attempting to back-port): {self._dict_str(tgt)}

For each **target** action decide whether it should be removed from the
sequence.

Definitions
  identical  – code text is effectively the same (ignore whitespace)
  opposites  – one action deletes and another inserts *the same* text
  irrelevant – touches unrelated code
  other      – none of the above

Return YAML with this schema (strict YAML, no commentary):

metadata:
  <target_id>:
    template_match: <template_id | ~>
    label        : <irrelevant|opposites|identical|other>
    tpl_vars     : [foo, bar]   # variables in matched template action (can be [])
    tgt_vars     : [foo, bar]   # variables in target action           (can be [])

Only include items that SHOULD BE DELETED, i.e.
  • label is 'irrelevant' or 'opposites', OR
  • template_match is ~, OR
  • tpl_vars and tgt_vars differ as sets.
"""
        yaml = self.agent.ask(
            prompt,
            output_format="yaml",
            stage="prune_actions"
        )

        meta = yaml.get("metadata", {}) or {}

        # ─── 1. helper to normalise a block of text ─────────────────────
        def _norm(a: Action) -> str:
            return " ".join(
                ln.text.strip().lower() for ln in a.lines
            )

        # ─── 2. verify ‘opposites’ really form pairs with same text ────
        norm_map = {aid: _norm(tgt[aid]) for aid in tgt}
        for aid, info in list(meta.items()):
            if info.get("label") != "opposites":
                continue
            twin   = next(
                (o for o, inf in meta.items()
                 if o != aid and inf.get("label") == "opposites"
                 and norm_map.get(o) == norm_map.get(aid)),
                None
            )
            if not twin:                     # lonely or mismatching – downgrade
                meta[aid]["label"] = "other"

        # ─── 3. build new action list  ──────────────────────────────────
        delete_ids = {
            k for k, m in meta.items()
            if m.get("label") in ("irrelevant", "opposites")
            or m.get("template_match") in (None, "~")
        }

        pruned = [
            a for idx, a in enumerate(actions)
            if f"0-{idx}" not in delete_ids
        ]

        # ─── 4. never return an empty list  ─────────────────────────────
        if not pruned:
            log.warning("[prune_actions] pruning removed all actions – "
                        "using originals instead")
            pruned = actions

        return pruned

    # 3. align actions via LLM
    def _align_actions(self, actions: list[Action]):
        action_dict = {f"{i}a": a for i, a in enumerate(actions)}

        yaml = self.agent.ask(
            f"""
This is a hunk of a patch in unified diff format, here called the template hunk:
{self.hunk}

It corresponds to a certain area of a package, which in another version is represented as CANDIDATE:
{self.candidate.context_str()}

CANDIDATE was produced by a call to candidate.context_str(), which produces a representation like:
line_no\\tmatch_type\\tline_of_code (excluding whitespace)

Think of the hunk as a template for how we might try to back-port the patch to the candidate.
A hunk can be understood as a series of actions performed in a given order. An action is either an INSERTION
or a DELETION.

An INSERTION corresponds to a contiguous set of lines of code that we want to inject into the candidate.
A DELETION is a contiguous set of lines of code that we want to remove from the candidate.

An alignment is our attempt to place actions in the candidate, in the correct order, based on where similar
lines of code occur in the template hunk.

In an alignment:
- An INSERTION is represented by one line number, which is the line AFTER WHICH the INSERTION will begin.
- A DELETION is represented by two line numbers, which are the range of code lines that will be deleted.

Examples:
INSERTION of 5 lines at line 23 inserts 5 lines **after** line 23.
DELETION  of 3 lines at lines 32-34 deletes lines 32, 33 and 34.

Here are the ACTIONS we want to perform on the candidate (in dict form):
{self._dict_str(action_dict)}

For each action, determine its alignment(s) in CANDIDATE:
- For INSERTION: output the line number after which to insert.
- For DELETION : output first and last line numbers to be deleted.
- Use the candidate's line numbers.

Output in strict YAML as follows:
alignments:
  <action_id>:
    insert_at:   # ~ if a DELETION, otherwise the line number after which to insert lines.
    delete_from: # ~ if an INSERTION, otherwise the first line number to delete.
    delete_to:   # ~ if an INSERTION, otherwise the last line number to delete.
""",
            output_format="yaml",
            stage="align_actions"
        )

        # ─────────────── normalise & validate YAML → list[{'action', 'interval'}]
        aligned: list[dict] = []

        for aid, meta in yaml.get("alignments", {}).items():
            if aid not in action_dict:
                continue

            # INSERTION (single coordinate)
            ins = meta.get("insert_at")
            if ins not in (None, "~"):
                try:
                    interval = [int(ins)]
                except (TypeError, ValueError):
                    continue
                aligned.append({"action": action_dict[aid], "interval": interval})
                continue

            # DELETION (two coordinates)
            frm = meta.get("delete_from")
            to  = meta.get("delete_to")
            if frm in (None, "~") or to in (None, "~"):
                continue
            try:
                interval = [int(frm), int(to)]
            except (TypeError, ValueError):
                continue
            aligned.append({"action": action_dict[aid], "interval": interval})

        return aligned

    # 4. weave & produce new Hunk
    def _weave(self, threads):
        """
        Build the back-ported hunk and give it the path of the file in
        which the candidate was found.  Overlapping DELETE/INSERT pairs
        are normalised first so we never clone a line we are about to
        remove.
        """
        from pathlib import Path

        # 0. normalize execution order / anchors
        threads = self._normalize_threads(threads)

        # 1. derive a relative path that matches the depth of the
        #    upstream filename but definitely exists in the target tree
        cand_path     = Path(self.candidate.path_to)
        upstream_tail = Path(self.hunk.filename)
        parts_needed  = len(upstream_tail.parts)
        rel_path      = Path(*cand_path.parts[-parts_needed:])

        # 2. weave the actions against the candidate’s context
        new_hunk = Hunk(str(rel_path))
        new_hunk.weave(self.candidate, threads)
        return new_hunk

    # ───────────────────────────────────────── public helpers
    def get_reports(self):
        """
        Returns (structural_error_list, triage_diff_string) and resets them
        so each Backporter instance is read exactly once.
        """
        errs, tri = self.struct_errors, self.triage_report
        self.struct_errors, self.triage_report = [], ""
        return errs, tri

    # ─────────────────────────────────────────────── tiny utils
    @staticmethod
    def _dict_str(d):
        return "\n".join(f"{k}:\n{v}" for k, v in d.items())

    @staticmethod
    def _extension_to_language(ext: str):
        return {
            ".py": "python",
            ".c": "c",
            ".cpp": "cpp",
            ".js": "javascript",
            ".java": "java",
        }.get(ext.lower(), "text")

    @staticmethod
    def _normalize_threads(threads: list[dict]) -> list[dict]:
        """
        Return a *new* thread list that the weaver can execute in one forward
        pass without duplicating lines.
    
        Steps performed
        1. For every INSERTION whose anchor k satisfies
               d_from - 1 ≤ k ≤ d_to
           of some DELETION [d_from, d_to],
           move the anchor to d_to (last line of the block).
    
        2. Re-order the list so that
             • all DELETION blocks appear first, ascending by d_from,
               each immediately followed by its rewritten INSERTIONs
             • all remaining INSERTIONs follow, ascending by anchor.
    
        3. Do **not** modify any interval except the anchor rewrite in (1).
           The original list object is left untouched (deep-copy semantics).
    
        The resulting list fulfils the invariant:
            walking candidate lines upward (low → high) and executing the
            actions in the returned order never encounters a reference to a
            line that has already been deleted.
        """
        deletions, insertions = [], []
    
        for t in threads:
            (deletions if len(t["interval"]) == 2 else insertions).append(t)
    
        ordered: list[dict] = []
    
        for d in sorted(deletions, key=lambda t: t["interval"][0]):
            d_from, d_to = d["interval"]
            ordered.append(d)
    
            victims = [
                ins for ins in insertions
                if d_from - 1 <= ins["interval"][0] <= d_to
            ]
            for ins in victims:
                ins["interval"][0] = d_to         
            ordered.extend(victims)
    
            insertions = [i for i in insertions if i not in victims]
    
        ordered.extend(sorted(insertions, key=lambda t: t["interval"][0]))
        return ordered
